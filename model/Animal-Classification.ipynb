{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kirtan/Documents/calgary-hacks-2025/model/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Could not find directory images_train",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/kirtan/Documents/calgary-hacks-2025/model/Animal-Classification.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kirtan/Documents/calgary-hacks-2025/model/Animal-Classification.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     ds_validation \u001b[39m=\u001b[39m ds_validation\u001b[39m.\u001b[39mcache()\u001b[39m.\u001b[39mprefetch(buffer_size\u001b[39m=\u001b[39mAUTOTUNE)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kirtan/Documents/calgary-hacks-2025/model/Animal-Classification.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m ds_train, ds_validation\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kirtan/Documents/calgary-hacks-2025/model/Animal-Classification.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m ds_train, ds_validation \u001b[39m=\u001b[39m get_datasets()\n",
      "\u001b[1;32m/Users/kirtan/Documents/calgary-hacks-2025/model/Animal-Classification.ipynb Cell 2\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kirtan/Documents/calgary-hacks-2025/model/Animal-Classification.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mget_datasets\u001b[39m():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kirtan/Documents/calgary-hacks-2025/model/Animal-Classification.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     directory \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mimages_train\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kirtan/Documents/calgary-hacks-2025/model/Animal-Classification.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     ds_train, ds_validation \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mpreprocessing\u001b[39m.\u001b[39;49mimage_dataset_from_directory(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kirtan/Documents/calgary-hacks-2025/model/Animal-Classification.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         directory,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kirtan/Documents/calgary-hacks-2025/model/Animal-Classification.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         labels\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39minferred\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kirtan/Documents/calgary-hacks-2025/model/Animal-Classification.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         label_mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mint\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kirtan/Documents/calgary-hacks-2025/model/Animal-Classification.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kirtan/Documents/calgary-hacks-2025/model/Animal-Classification.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         image_size\u001b[39m=\u001b[39;49m(image_height, image_width),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kirtan/Documents/calgary-hacks-2025/model/Animal-Classification.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kirtan/Documents/calgary-hacks-2025/model/Animal-Classification.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         seed\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kirtan/Documents/calgary-hacks-2025/model/Animal-Classification.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.20\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kirtan/Documents/calgary-hacks-2025/model/Animal-Classification.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         subset\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mboth\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kirtan/Documents/calgary-hacks-2025/model/Animal-Classification.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kirtan/Documents/calgary-hacks-2025/model/Animal-Classification.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     AUTOTUNE \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mAUTOTUNE\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kirtan/Documents/calgary-hacks-2025/model/Animal-Classification.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     ds_train \u001b[39m=\u001b[39m ds_train\u001b[39m.\u001b[39mcache()\u001b[39m.\u001b[39mshuffle(\u001b[39m2200\u001b[39m)\u001b[39m.\u001b[39mprefetch(buffer_size\u001b[39m=\u001b[39mAUTOTUNE)\n",
      "File \u001b[0;32m~/Documents/calgary-hacks-2025/model/.venv/lib/python3.12/site-packages/keras/src/utils/image_dataset_utils.py:232\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m seed \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     seed \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m1e6\u001b[39m)\n\u001b[0;32m--> 232\u001b[0m image_paths, labels, class_names \u001b[39m=\u001b[39m dataset_utils\u001b[39m.\u001b[39;49mindex_directory(\n\u001b[1;32m    233\u001b[0m     directory,\n\u001b[1;32m    234\u001b[0m     labels,\n\u001b[1;32m    235\u001b[0m     formats\u001b[39m=\u001b[39;49mALLOWLIST_FORMATS,\n\u001b[1;32m    236\u001b[0m     class_names\u001b[39m=\u001b[39;49mclass_names,\n\u001b[1;32m    237\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m    238\u001b[0m     seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    239\u001b[0m     follow_links\u001b[39m=\u001b[39;49mfollow_links,\n\u001b[1;32m    240\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    241\u001b[0m )\n\u001b[1;32m    243\u001b[0m \u001b[39mif\u001b[39;00m label_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(class_names) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    244\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    245\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mWhen passing `label_mode=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`, there must be exactly 2 \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    246\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mclass_names. Received: class_names=\u001b[39m\u001b[39m{\u001b[39;00mclass_names\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/calgary-hacks-2025/model/.venv/lib/python3.12/site-packages/keras/src/utils/dataset_utils.py:530\u001b[0m, in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links, verbose)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[39mif\u001b[39;00m labels \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minferred\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    529\u001b[0m     subdirs \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 530\u001b[0m     \u001b[39mfor\u001b[39;00m subdir \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(tf\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mgfile\u001b[39m.\u001b[39;49mlistdir(directory)):\n\u001b[1;32m    531\u001b[0m         \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m    532\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m subdir\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/calgary-hacks-2025/model/.venv/lib/python3.12/site-packages/tensorflow/python/lib/io/file_io.py:768\u001b[0m, in \u001b[0;36mlist_directory_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns a list of entries contained within a directory.\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \n\u001b[1;32m    755\u001b[0m \u001b[39mThe list is in arbitrary order. It does not contain the special entries \".\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[39m  errors.NotFoundError if directory doesn't exist\u001b[39;00m\n\u001b[1;32m    766\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_directory(path):\n\u001b[0;32m--> 768\u001b[0m   \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError(\n\u001b[1;32m    769\u001b[0m       node_def\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    770\u001b[0m       op\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    771\u001b[0m       message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not find directory \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(path))\n\u001b[1;32m    773\u001b[0m \u001b[39m# Convert each element to string, since the return values of the\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[39m# vector of string should be interpreted as strings, not bytes.\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    776\u001b[0m     compat\u001b[39m.\u001b[39mas_str_any(filename)\n\u001b[1;32m    777\u001b[0m     \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m _pywrap_file_io\u001b[39m.\u001b[39mGetChildren(compat\u001b[39m.\u001b[39mpath_to_bytes(path))\n\u001b[1;32m    778\u001b[0m ]\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Could not find directory images_train"
     ]
    }
   ],
   "source": [
    "image_height = 180\n",
    "image_width = 180\n",
    "batch_size = 32\n",
    "num_classes = 21  # Update this based on actual classes\n",
    "\n",
    "# Load Dataset\n",
    "def get_datasets():\n",
    "    directory = \"../images_train/\"\n",
    "    ds_train, ds_validation = keras.preprocessing.image_dataset_from_directory(\n",
    "        directory,\n",
    "        labels='inferred',\n",
    "        label_mode='int',\n",
    "        batch_size=batch_size,\n",
    "        image_size=(image_height, image_width),\n",
    "        shuffle=True,\n",
    "        seed=50,\n",
    "        validation_split=0.20,\n",
    "        subset=\"both\"\n",
    "    )\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    ds_train = ds_train.cache().shuffle(2200).prefetch(buffer_size=AUTOTUNE)\n",
    "    ds_validation = ds_validation.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds_train, ds_validation\n",
    "\n",
    "ds_train, ds_validation = get_datasets()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna Optimization\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.3, 0.6)\n",
    "    filters_1 = trial.suggest_int(\"filters_1\", 16, 64, step=16)\n",
    "    filters_2 = trial.suggest_int(\"filters_2\", 32, 128, step=32)\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Rescaling(1./255, input_shape=(image_height, image_width, 3)),\n",
    "        tf.keras.layers.Conv2D(filters_1, (4, 4), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(filters_2, (4, 4), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"sparse_categorical_accuracy\"]\n",
    "    )\n",
    "\n",
    "    history = model.fit(ds_train, validation_data=ds_validation, epochs=10, verbose=0)\n",
    "    \n",
    "    return max(history.history[\"val_sparse_categorical_accuracy\"])\n",
    "\n",
    "# Run Optuna Study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Get Best Parameters\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Final Model with Best Parameters\n",
    "final_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255, input_shape=(image_height, image_width, 3)),\n",
    "    tf.keras.layers.Conv2D(best_params[\"filters_1\"], (4, 4), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(best_params[\"filters_2\"], (4, 4), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(best_params[\"dropout_rate\"]),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "final_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(best_params[\"learning_rate\"]),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"sparse_categorical_accuracy\"]\n",
    ")\n",
    "\n",
    "history = final_model.fit(ds_train, epochs=40, validation_data=ds_validation)\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend([\"Training\", \"Validation\"])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
